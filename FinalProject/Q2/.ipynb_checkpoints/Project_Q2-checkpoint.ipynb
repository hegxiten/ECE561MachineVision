{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "u2P8rerJEvB-",
    "outputId": "5a25afd3-9c44-4d0e-f860-b5b3e7cb5a47"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\py36cv\\lib\\site-packages\\tqdm\\autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n",
      "Using cache found in C:\\Users\\wangz/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 2413\n",
      "Testing Data Size: 805\n"
     ]
    }
   ],
   "source": [
    "# Use the testing mode for evaluation (the whole ready-to-go model), since we \n",
    "# are not contributing to the model itself\n",
    "# If user would like to use this acceleration, select the menu option \n",
    "# \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and\n",
    "# click \"SAVE\"\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import inspect\n",
    "import time\n",
    "from torch import nn, optim\n",
    "import torch, os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, CenterCrop, Grayscale\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "from random import sample\n",
    "\n",
    "# selected ResNet34 as the model\n",
    "model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "classes = [\"Apple Golden 1\", \"Apple Golden 2\", \"Apple Golden 3\", \"Apple Granny Smith\", \"Apple Pink Lady\"]\n",
    "\n",
    "def gettrainfiles(): \n",
    "    _files, classidx, _filefullpath = [], [], []\n",
    "    for cls in range(len(classes)):\n",
    "        classidx += [cls] * len(os.listdir(traindir + '\\\\' + classes[cls]))\n",
    "        _files += os.listdir(traindir + '\\\\' + classes[cls])\n",
    "        for f in os.listdir(traindir + '\\\\' + classes[cls]):\n",
    "            _filefullpath.append(traindir + '\\\\' + classes[cls] + '\\\\' + f)\n",
    "    return [_files, classidx, _filefullpath]\n",
    "def gettestfiles(): \n",
    "    _files, classidx, _filefullpath = [], [], []\n",
    "    for cls in range(len(classes)):\n",
    "        classidx += [cls] * len(os.listdir(testdir + '\\\\' + classes[cls]))\n",
    "        _files += os.listdir(testdir + '\\\\' + classes[cls])\n",
    "        for f in os.listdir(testdir + '\\\\' + classes[cls]):\n",
    "            _filefullpath.append(testdir + '\\\\' + classes[cls] + '\\\\' + f)\n",
    "    return [_files, classidx, _filefullpath]\n",
    "\n",
    "root_path = 'C:\\\\Users\\\\wangz\\\\Documents\\\\GitHub\\\\ECE561MachineVision\\\\FinalProject\\\\Q2\\\\fruits\\\\fruits-360_dataset\\\\fruits-360'\n",
    "traindir = root_path + '\\\\Training'\n",
    "testdir = root_path + '\\\\Test'\n",
    "\n",
    "trainfiles = gettrainfiles()[0]\n",
    "trainclasses = gettrainfiles()[1]\n",
    "trainfilefullpaths = gettrainfiles()[2]\n",
    "testfiles = gettestfiles()[0]\n",
    "testclasses = gettestfiles()[1]\n",
    "testfilefullpaths = gettestfiles()[2]\n",
    "\n",
    "print(\"Training Data Size: \" + str(len(trainfiles)))\n",
    "print(\"Testing Data Size: \" + str(len(testfiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition Experiment Using ImageNet pre-trained model on the Fruit360 Data:\n",
      "\t True Fruit Class \t Predicted ImageNet Class\n",
      "\t ################ \t ########################\n",
      "\n",
      "\t Apple Golden 2 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Pink Lady \t\t pomegranate\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Pink Lady \t\t pomegranate\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Pink Lady \t\t pomegranate\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t lemon\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Pink Lady \t\t pomegranate\n",
      "\t Apple Pink Lady \t\t orange\n",
      "\t Apple Golden 2 \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t lemon\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t lemon\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t lemon\n",
      "\t Apple Golden 2 \t\t Granny Smith\n",
      "\t Apple Pink Lady \t\t orange\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Pink Lady \t\t pomegranate\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Golden 2 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Pink Lady \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t custard apple\n",
      "\t Apple Golden 2 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t lemon\n",
      "\t Apple Golden 3 \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t Granny Smith\n",
      "\t Apple Golden 1 \t\t lemon\n",
      "\t Apple Pink Lady \t\t pomegranate\n",
      "\t Apple Granny Smith \t\t Granny Smith\n",
      "\t Apple Golden 2 \t\t Granny Smith\n"
     ]
    }
   ],
   "source": [
    "# Q2 (a) recognition experiment:\n",
    "# here I have not yet started fine-tuning the network \n",
    "with open(root_path + '\\\\' + 'imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_true, test_pred = [], []\n",
    "sample_50_image_idx = [x for x in sample(range(len(gettestfiles()[0])),50)]\n",
    "input_images = sample_50_image_paths = [Image.open(gettestfiles()[2][x]) for x in sample_50_image_idx]\n",
    "test_true = [classes[testclasses[x]] for x in sample_50_image_idx]\n",
    "for i in range(len(input_images)):\n",
    "    preprocess = transforms.Compose([\n",
    "                  transforms.CenterCrop(224),\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                       std=[0.229, 0.224, 0.225]),])\n",
    "    input_tensor = preprocess(input_images[i])\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    _, index = torch.max(output, 1)\n",
    "    # The output has unnormalized scores. To get probabilities, run a \n",
    "    # softmax on it (to normalize the scores to probability).\n",
    "    percentage = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
    "    pred_label_i = labels[index[0]]\n",
    "    test_pred.append(pred_label_i)\n",
    "\n",
    "print(\"Recognition Experiment Using ImageNet pre-trained model on the Fruit360 Data:\")\n",
    "print('\\t', \"True Fruit Class\", '\\t', \"Predicted ImageNet Class\")\n",
    "print('\\t', \"################\", '\\t', \"########################\\n\")\n",
    "\n",
    "for i in range(len(sample_50_image_idx)):\n",
    "    print('\\t', test_true[i], '\\t\\t', test_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional Utilities\n",
    "class FiveClassFruit(Dataset):\n",
    "    def __init__(self, filelist, classlist, fullfilepath, transform=None):\n",
    "        self.filelist = filelist\n",
    "        self.classlist = classlist\n",
    "        self.fullfilepath = fullfilepath\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        assert len(self.filelist) == len(self.classlist) == len(self.fullfilepath)\n",
    "        return len(self.filelist)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.filelist[idx]            \n",
    "        fullname = self.fullfilepath[idx]\n",
    "        cls = self.classlist[idx]\n",
    "        image = Image.open(fullname)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return [image, cls]\n",
    "\n",
    "def get_data_loaders(train_batch_size=8, val_batch_size=2):    \n",
    "    data_transform = Compose([Resize((224,224)),\n",
    "                              CenterCrop(224),\n",
    "                              ToTensor(), \n",
    "                              Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    train_loader = DataLoader(FiveClassFruit(trainfiles, \n",
    "                                             trainclasses,\n",
    "                                             trainfilefullpaths, \n",
    "                                             transform=data_transform),\n",
    "                              batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(FiveClassFruit(testfiles, \n",
    "                                           testclasses,\n",
    "                                           testfilefullpaths, \n",
    "                                           transform=data_transform),\n",
    "                            batch_size=val_batch_size, shuffle=False)\n",
    "    # use the train dataset for both train and validation (no labels on testset)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def calculate_metric(metric_fn, true_y, pred_y):\n",
    "    # multi class problems need to have averaging method\n",
    "    if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
    "        return metric_fn(true_y, pred_y, average=\"macro\")\n",
    "    else:\n",
    "        return metric_fn(true_y, pred_y)\n",
    "    \n",
    "def print_scores(p, r, f1, a, batch_size):\n",
    "    for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
    "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")\n",
    "\n",
    "def train_and_val(model):\n",
    "    batches = len(train_loader)\n",
    "    val_batches = len(val_loader)\n",
    "\n",
    "    # loop for every epoch (training + evaluation)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        # progress bar\n",
    "        progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
    "\n",
    "        # ----------------- TRAINING  -------------------- \n",
    "        # set model to training\n",
    "        model.train()\n",
    "        for i, data in progress:\n",
    "            X, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # training step for single batch\n",
    "            model.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = loss_function(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # getting training quality data\n",
    "            current_loss = loss.item()\n",
    "            total_loss += current_loss\n",
    "\n",
    "            # updating progress bar\n",
    "            progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
    "\n",
    "        # releasing unceseccary memory in GPU\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # ----------------- VALIDATION  ----------------- \n",
    "        val_losses = 0\n",
    "        precision, recall, f1, accuracy = [], [], [], []\n",
    "        true_cls, pred_cls = [], []\n",
    "        # set model to evaluating (testing)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_loader):\n",
    "                X, y = data[0].to(device), data[1].to(device)\n",
    "                # Get's the prediction (outputs) from the network\n",
    "                outputs = model(X)\n",
    "                val_losses += loss_function(outputs, y)\n",
    "\n",
    "                predicted_classes = torch.max(outputs, 1)[1] # get class from network's prediction\n",
    "                true_cls.extend(y.cpu())\n",
    "                pred_cls.extend(predicted_classes.cpu())\n",
    "\n",
    "                # calculate P/R/F1/A metrics for batch\n",
    "                for acc, metric in zip((precision, recall, f1, accuracy), \n",
    "                                       (precision_score, recall_score, f1_score, accuracy_score)):\n",
    "                    acc.append(calculate_metric(metric, \n",
    "                                                y.cpu(), predicted_classes.cpu()))\n",
    "            print(confusion_matrix(true_cls, pred_cls, labels=[0,1,2,3,4]))\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
    "            print_scores(precision, recall, f1, accuracy, val_batches)\n",
    "            losses.append(total_loss/batches) # for plotting learning curve\n",
    "    print(f\"Training time: {time.time()-start_ts}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\wangz/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4825fdc2a2e4f98afd9ad86397afc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loss: ', max=38, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[164   0   0   0   0]\n",
      " [  0 164   0   0   0]\n",
      " [  0   6 155   0   0]\n",
      " [  0   0   6 158   0]\n",
      " [  0   0   0   0 152]]\n",
      "Epoch 1/3, training loss: 0.7224029741789165, validation loss: 0.32721996307373047\n",
      "\t     precision: 0.9314\n",
      "\t        recall: 0.9240\n",
      "\t            F1: 0.9274\n",
      "\t      accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92511dbad0c46cd85ac048429056246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loss: ', max=38, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5cd9a30f8c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mtrain_and_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-af35a25b4fdf>\u001b[0m in \u001b[0;36mtrain_and_val\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m# getting training quality data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use ResNet18 for fine-tuning fully connected layer to achieve the best results\n",
    "model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "# Fine-tuning: First modify the model configurations\n",
    "# set all weights to be fixed: not back-propogating gradients\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "# set the fully connected layer to be trainable: require back-propogation of gradients\n",
    "for params in model.fc.parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "# set the number of classes as 5 (required by the project)\n",
    "# replace the last layer with our custmozied linear layer with 5 out features (5 classes)\n",
    "class_num = len(classes)\n",
    "channel_in = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=channel_in, out_features=class_num)\n",
    "\n",
    "epochs = 3\n",
    "train_loader, val_loader = get_data_loaders(64,16)# put your data loader here, play with batch size to satisfy cuda\n",
    "loss_function = nn.CrossEntropyLoss() # your loss function, cross entropy works well for multi-class problems\n",
    "\n",
    "# construct the stochastic gradient descent opimizer \n",
    "# and filter-out those parameters requiring gradient inputs (previsou layers)\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=0.1)\n",
    "\n",
    "# optimizer, try Adam this time to have a taste\n",
    "# optimize the full connection layer only, magic numbers from online resource\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "start_ts = time.time()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.cuda()\n",
    "\n",
    "losses = []\n",
    "\n",
    "train_and_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1RBxcvnJm3OP",
    "outputId": "8ee48c98-7828-4d0e-f086-dc886cd5fd5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\wangz/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba4a87e90bb4d47b042dcc4171e721a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loss: ', max=38, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[164   0   0   0   0]\n",
      " [  0 164   0   0   0]\n",
      " [  0  92  63   6   0]\n",
      " [  0   2   0 162   0]\n",
      " [  0   0   0   0 152]]\n",
      "Epoch 1/3, training loss: 57.803911309493216, validation loss: 5.301993370056152\n",
      "\t     precision: 0.8764\n",
      "\t        recall: 0.8278\n",
      "\t            F1: 0.8357\n",
      "\t      accuracy: 0.8775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f89507f12f24dabb62a40cd18de0489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loss: ', max=38, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e9c58eb18aa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mtrain_and_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;31m# batches = len(train_loader)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# val_batches = len(val_loader)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-af35a25b4fdf>\u001b[0m in \u001b[0;36mtrain_and_val\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m# getting training quality data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use Alexnet for testing Dropout Regularization and Batch-Normalization\n",
    "# Alexnet already uses 0.5 in three dropout layers\n",
    "# Modify the classfier[6] of Alexnet to fine tune\n",
    "model = torch.hub.load('pytorch/vision', 'alexnet', pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, len(classes))\n",
    "\n",
    "# set all weights to be fixed: not back-propogating gradients\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "# set the fully connected layer to be trainable: require back-propogation of gradients\n",
    "for params in model.classifier[6].parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "epochs = 3\n",
    "train_loader, val_loader = get_data_loaders(64,16)# put your data loader here, play with batch size to satisfy cuda\n",
    "loss_function = nn.CrossEntropyLoss() # your loss function, cross entropy works well for multi-class problems\n",
    "\n",
    "# construct the stochastic gradient descent opimizer \n",
    "# and filter-out those parameters requiring gradient inputs (previsou layers)\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=0.1)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "start_ts = time.time()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.cuda()\n",
    "\n",
    "losses = []\n",
    "\n",
    "train_and_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rzaux5ZqX14N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\wangz/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 4.00 GiB total capacity; 2.85 GiB already allocated; 69.90 MiB free; 17.33 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-fbc09fb90d87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36cv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \"\"\"\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36cv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36cv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36cv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36cv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \"\"\"\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 4.00 GiB total capacity; 2.85 GiB already allocated; 69.90 MiB free; 17.33 MiB cached)"
     ]
    }
   ],
   "source": [
    "# Use Alexnet for showing the differences (effects) of dropouts and batchnorms\n",
    "model = AlexNet(num_classes=len(classes))\n",
    "model = torch.hub.load('pytorch/vision', 'alexnet', pretrained=True)\n",
    "# deactivate the Dropout to see if there is difference or not\n",
    "model.classifier[0] = nn.Identity()\n",
    "\n",
    "epochs = 5\n",
    "train_loader, val_loader = get_data_loaders(64,16)# put your data loader here, play with batch size to satisfy cuda\n",
    "loss_function = nn.CrossEntropyLoss() # your loss function, cross entropy works well for multi-class problems\n",
    "\n",
    "# construct the stochastic gradient descent opimizer \n",
    "# and filter-out those parameters requiring gradient inputs (previsou layers)\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=0.1)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "start_ts = time.time()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.cuda()\n",
    "\n",
    "losses = []\n",
    "\n",
    "train_and_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.5, inplace=False)\n",
       "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for p in model.classifier[6].parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "    nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    ReLU(inplace=True),\n",
    "    MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW5_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
