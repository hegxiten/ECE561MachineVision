{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "DATA_DIR = \"C:/Users/wangz/Documents/GitHub/ECE561MachineVision/FinalProject/Q4\"\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(DATA_DIR + '/data.txt', skiprows=18, engine=\"python\", names=['Time', 'CH1', 'CH2'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = df1.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.max(datas)\n",
    "min_value = np.min(datas)\n",
    "scalar = max_value - min_value\n",
    "datas = list(map(lambda x: x / scalar, datas))\n",
    "\n",
    "def creat_dataset(dataset,look_back):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        data_x.append(dataset[i:i+look_back])\n",
    "        data_y.append(dataset[i+look_back])\n",
    "    return np.asarray(data_x), np.asarray(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX, dataY = creat_dataset(datas,2)\n",
    "\n",
    "train_size = int(len(dataX)*0.7)\n",
    "\n",
    "x_train = dataX[:train_size] #训练数据\n",
    "y_train = dataY[:train_size] #训练数据目标值\n",
    "\n",
    "x_train = x_train.reshape(-1, 1, 2) #将训练数据调整成pytorch中lstm算法的输入维度\n",
    "y_train = y_train.reshape(-1, 1, 1)  #将目标值调整成pytorch中lstm算法的输出维度\n",
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        self.lstm = nn.LSTM(2,6,2) #输入数据2个特征维度，6个隐藏层维度，2个LSTM串联，第二个LSTM接收第一个的计算结果\n",
    "        self.out = nn.Linear(6,1) #线性拟合，接收数据的维度为6，输出数据的维度为1\n",
    "    def forward(self,x):\n",
    "        x1,_ = self.lstm(x)\n",
    "        a,b,c = x1.shape\n",
    "        out = self.out(x1.view(-1,c)) #因为线性层输入的是个二维数据，所以此处应该将lstm输出的三维数据x1调整成二维数据，最后的特征维度不能变\n",
    "        out1 = out.view(a,b,-1) #因为是循环神经网络，最后的时候要把二维的out调整成三维数据，下一次循环使用\n",
    "        return out1\n",
    "\n",
    "rnn = RNN()\n",
    "\n",
    "#参数寻优，计算损失函数\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(),lr = 0.02)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    var_x = Variable(x_train).type(torch.FloatTensor)\n",
    "    var_y = Variable(y_train).type(torch.FloatTensor)\n",
    "    out = rnn(var_x)\n",
    "    loss = loss_func(out,var_y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1)%100==0:\n",
    "        print('Epoch:{}, Loss:{:.5f}'.format(i+1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
